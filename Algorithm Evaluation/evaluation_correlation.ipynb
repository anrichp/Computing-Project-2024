{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import textstat\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define the root directory and the subdirectories with the corresponding human readability levels\n",
    "root_dir = \"Texts-SeparatedByReadingLevel\"\n",
    "directories = {\n",
    "    \"Int-Txt\": \"Intermediate\",\n",
    "    \"Ele-Txt\": \"Elementary\",\n",
    "    \"Adv-Txt\": \"Advanced\"\n",
    "}\n",
    "\n",
    "# List to store the readability scores\n",
    "readability_data = []\n",
    "\n",
    "# Function to get readability scores for a given text\n",
    "def get_readability_scores(text):\n",
    "    try:\n",
    "        scores = {\n",
    "            \"Flesch Reading Ease\": textstat.flesch_reading_ease(text),\n",
    "            \"SMOG Index\": textstat.smog_index(text),\n",
    "            \"Flesch-Kincaid Grade\": textstat.flesch_kincaid_grade(text),\n",
    "            \"Coleman-Liau Index\": textstat.coleman_liau_index(text),\n",
    "            \"Automated Readability Index\": textstat.automated_readability_index(text),\n",
    "            \"Dale-Chall Readability Score\": textstat.dale_chall_readability_score(text),\n",
    "            \"Linsear Write Formula\": textstat.linsear_write_formula(text),\n",
    "            \"Gunning Fog Index\": textstat.gunning_fog(text)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error calculating readability scores: {e}\")\n",
    "        scores = {\n",
    "            \"Flesch Reading Ease\": None,\n",
    "            \"SMOG Index\": None,\n",
    "            \"Flesch-Kincaid Grade\": None,\n",
    "            \"Coleman-Liau Index\": None,\n",
    "            \"Automated Readability Index\": None,\n",
    "            \"Dale-Chall Readability Score\": None,\n",
    "            \"Linsear Write Formula\": None,\n",
    "            \"Gunning Fog Index\": None\n",
    "        }\n",
    "    return scores\n",
    "\n",
    "# Iterate through the directories\n",
    "for dir_name, readability_level in directories.items():\n",
    "    dir_path = os.path.join(root_dir, dir_name)\n",
    "    for filename in os.listdir(dir_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(dir_path, filename)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    text = file.read()\n",
    "                    scores = get_readability_scores(text)\n",
    "                    scores[\"Filename\"] = filename\n",
    "                    scores[\"Human Evaluation\"] = readability_level\n",
    "                    readability_data.append(scores)\n",
    "                    logging.info(f\"Processed file: {filename} in {readability_level} level\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error reading file {filename}: {e}\")\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(readability_data)\n",
    "\n",
    "# Convert human evaluations to numeric scores\n",
    "df['Human Evaluation Numeric'] = df['Human Evaluation'].map({\n",
    "    'Elementary': 1,\n",
    "    'Intermediate': 2,\n",
    "    'Advanced': 3\n",
    "})\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "numeric_columns = [\n",
    "    \"Flesch Reading Ease\",\n",
    "    \"SMOG Index\",\n",
    "    \"Flesch-Kincaid Grade\",\n",
    "    \"Coleman-Liau Index\",\n",
    "    \"Automated Readability Index\",\n",
    "    \"Dale-Chall Readability Score\",\n",
    "    \"Linsear Write Formula\",\n",
    "    \"Gunning Fog Index\",\n",
    "    \"Human Evaluation Numeric\"\n",
    "]\n",
    "correlation_matrix = df[numeric_columns].corr(method='pearson')\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# If you want to specifically see the correlation of readability scores with human evaluations\n",
    "print(correlation_matrix['Human Evaluation Numeric'])\n",
    "\n",
    "# Export the DataFrame and correlation matrix to an Excel file\n",
    "with pd.ExcelWriter(\"readability_assessments_with_correlation.xlsx\") as writer:\n",
    "    df.to_excel(writer, sheet_name='Readability Scores', index=False)\n",
    "    correlation_matrix.to_excel(writer, sheet_name='Correlation Matrix')\n",
    "\n",
    "logging.info(f\"Readability assessments and correlation matrix exported to readability_assessments_with_correlation.xlsx\")\n",
    "\n",
    "# Visualize the Pearson correlation matrix using seaborn\n",
    "plt.figure(figsize=(10, 8))\n",
    "heatmap = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\n",
    "plt.title('Pearson Correlation Matrix of Readability Scores')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the heatmap to a file\n",
    "heatmap_fig = heatmap.get_figure()\n",
    "heatmap_fig.savefig(\"pearson_correlation_heatmap.png\")\n",
    "\n",
    "logging.info(\"Pearson correlation heatmap saved to pearson_correlation_heatmap.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
